--- 考察 ---
実データを用いた分類タスクでの解釈性比較実験の結果：

【線形モデル（ロジスティック回帰）の解釈性】
1. 直接的な解釈: 係数は各特徴量が結果に与える影響の大きさと方向を直接示します。
2. 単位あたりの影響: 「特徴量Xが1単位増加すると、ログオッズがβだけ変化する」
   という明確な数値的関係を提供します。
3. グローバルな説明: モデル全体の動作を一つの式で表現できます。
4. 規制対応: 金融業界などの規制が厳しい分野で求められる「説明可能性」を満たします。

【GDBTモデル（LightGBM + SHAP）の解釈性】
1. 事後的な説明: SHAPは学習後にモデルの予測を分析する手法です。
2. 個別予測の説明: 各予測に対する特徴量の貢献度を視覚的に示します。
3. 複雑な相互作用: 特徴量間の複雑な相互作用も捉えることができます。
4. 局所的な説明: 個々のサンプルに対する説明は詳細ですが、
   モデル全体の動作原理は依然として「ブラックボックス」です。

【解釈性の根本的な違い】
- 線形モデル: 「なぜそう予測するのか」をモデル構造自体が説明
- GDBTモデル: 「どのような予測をしたのか」を事後的に分析

【実用的な示唆】
1. 規制の厳しい分野（金融、医療等）: 線形モデルの透明性が重要
2. 高精度が最優先の分野: GDBTモデル + SHAP の組み合わせが有効
3. ビジネス理解重視: 線形モデルの直接的な解釈性が価値を持つ

実験データ: UCIドイツ信用データセット（代替：人工分類データ）
評価指標: Accuracy, F1 Score, ROC AUC
解釈性手法: 係数分析（線形）、SHAP値分析（GDBT）
