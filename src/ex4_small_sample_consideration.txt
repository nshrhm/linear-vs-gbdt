
--- 考察 ---
小規模データセットでは、モデルの過学習への耐性が重要になります。

1. GDBTモデル: 訓練データに対しては非常に低い誤差（高い精度）を示しますが、
   テストデータでは誤差が大幅に悪化する傾向があります。これは、モデルが
   訓練データのノイズまで過剰に学習してしまい、未知のデータに対する
   汎化性能を失っている（過学習）ことを示しています。

2. 線形モデル: 単純な線形回帰も過学習の傾向を見せることがありますが、
   RidgeやLassoといった正則化付きのモデルは、訓練誤差とテスト誤差の差が
   比較的小さく、より安定した性能を示します。これは、正則化がモデルの
   複雑さにペナルティを課すことで、過学習を抑制しているためです。

結論として、サンプル数が限られている状況では、複雑なGDBTモデルは
過学習のリスクが高く、注意深いハイパーパラメータ調整が不可欠です。
一方で、正則化付きの線形モデルは、そのシンプルさと過学習への耐性から、
より信頼性の高い選択肢となり得ます。

実験設定:
- サンプル数: 100 (訓練70, テスト30)
- 特徴量数: 50 (情報のある特徴量: 10)
- 特徴量数 > サンプル数の高次元小標本問題
- 過学習指標: 訓練・テスト誤差の差
